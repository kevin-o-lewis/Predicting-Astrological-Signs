{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d7625c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b876500d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mostly_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5877f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48890 entries, 0 to 48889\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            48890 non-null  int64  \n",
      " 1   age                   48890 non-null  int64  \n",
      " 2   status                48890 non-null  object \n",
      " 3   sex                   48890 non-null  object \n",
      " 4   orientation           48890 non-null  object \n",
      " 5   body_type             48890 non-null  object \n",
      " 6   diet                  48890 non-null  object \n",
      " 7   drinks                48890 non-null  object \n",
      " 8   drugs                 48890 non-null  object \n",
      " 9   education             48890 non-null  object \n",
      " 10  ethnicity             44945 non-null  object \n",
      " 11  height                48890 non-null  float64\n",
      " 12  job                   48890 non-null  object \n",
      " 13  offspring             48890 non-null  object \n",
      " 14  pets                  48890 non-null  object \n",
      " 15  religion              48890 non-null  object \n",
      " 16  sign                  48890 non-null  object \n",
      " 17  smokes                48890 non-null  object \n",
      " 18  speaks                48860 non-null  object \n",
      " 19  essay0                44796 non-null  object \n",
      " 20  essay1                43464 non-null  object \n",
      " 21  essay2                42041 non-null  object \n",
      " 22  essay3                40828 non-null  object \n",
      " 23  essay4                41301 non-null  object \n",
      " 24  essay5                41292 non-null  object \n",
      " 25  essay6                38968 non-null  object \n",
      " 26  essay7                40068 non-null  object \n",
      " 27  essay8                34618 non-null  object \n",
      " 28  essay9                39700 non-null  object \n",
      " 29  sign_actual           48890 non-null  object \n",
      " 30  sign_seriousness      48890 non-null  object \n",
      " 31  religion_actual       48890 non-null  object \n",
      " 32  religion_seriousness  48890 non-null  object \n",
      "dtypes: float64(1), int64(2), object(30)\n",
      "memory usage: 12.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b7630e",
   "metadata": {},
   "outputs": [],
   "source": [
    "essays = df.iloc[:, 19:29]\n",
    "essays.fillna(\".\", inplace=True)\n",
    "essays['essays_combined'] = essays['essay0']\n",
    "for col in essays.columns[1:]:\n",
    "    essays['essays_combined'] += essays[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45ec1566",
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmed_df = df.drop(columns={'Unnamed: 0', \n",
    "                 'sign', \n",
    "                 'religion', \n",
    "                 'essay0', \n",
    "                 'essay1', \n",
    "                 'essay2', \n",
    "                 'essay3', \n",
    "                 'essay4', \n",
    "                 'essay5', \n",
    "                 'essay6', \n",
    "                 'essay7', \n",
    "                 'essay8', \n",
    "                 'essay9',\n",
    "                 'sign_actual'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cdc4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df = pd.get_dummies(trimmed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70491f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['age',\n",
       " 'height',\n",
       " 'status_available',\n",
       " 'status_married',\n",
       " 'status_seeing someone',\n",
       " 'status_single',\n",
       " 'status_unknown',\n",
       " 'sex_f',\n",
       " 'sex_m',\n",
       " 'orientation_bisexual',\n",
       " 'orientation_gay',\n",
       " 'orientation_straight',\n",
       " 'body_type_a little extra',\n",
       " 'body_type_athletic',\n",
       " 'body_type_average',\n",
       " 'body_type_curvy',\n",
       " 'body_type_fit',\n",
       " 'body_type_full figured',\n",
       " 'body_type_jacked',\n",
       " 'body_type_no_answer',\n",
       " 'body_type_overweight',\n",
       " 'body_type_rather not say',\n",
       " 'body_type_skinny',\n",
       " 'body_type_thin',\n",
       " 'body_type_used up',\n",
       " 'diet_anything',\n",
       " 'diet_halal',\n",
       " 'diet_kosher',\n",
       " 'diet_mostly anything',\n",
       " 'diet_mostly halal',\n",
       " 'diet_mostly kosher',\n",
       " 'diet_mostly other',\n",
       " 'diet_mostly vegan',\n",
       " 'diet_mostly vegetarian',\n",
       " 'diet_no_answer',\n",
       " 'diet_other',\n",
       " 'diet_strictly anything',\n",
       " 'diet_strictly halal',\n",
       " 'diet_strictly kosher',\n",
       " 'diet_strictly other',\n",
       " 'diet_strictly vegan',\n",
       " 'diet_strictly vegetarian',\n",
       " 'diet_vegan',\n",
       " 'diet_vegetarian',\n",
       " 'drinks_desperately',\n",
       " 'drinks_no_answer',\n",
       " 'drinks_not at all',\n",
       " 'drinks_often',\n",
       " 'drinks_rarely',\n",
       " 'drinks_socially',\n",
       " 'drinks_very often',\n",
       " 'drugs_never',\n",
       " 'drugs_no_answer',\n",
       " 'drugs_often',\n",
       " 'drugs_sometimes',\n",
       " 'education_college/university',\n",
       " 'education_dropped out of college/university',\n",
       " 'education_dropped out of high school',\n",
       " 'education_dropped out of law school',\n",
       " 'education_dropped out of masters program',\n",
       " 'education_dropped out of med school',\n",
       " 'education_dropped out of ph.d program',\n",
       " 'education_dropped out of space camp',\n",
       " 'education_dropped out of two-year college',\n",
       " 'education_graduated from college/university',\n",
       " 'education_graduated from high school',\n",
       " 'education_graduated from law school',\n",
       " 'education_graduated from masters program',\n",
       " 'education_graduated from med school',\n",
       " 'education_graduated from ph.d program',\n",
       " 'education_graduated from space camp',\n",
       " 'education_graduated from two-year college',\n",
       " 'education_high school',\n",
       " 'education_law school',\n",
       " 'education_masters program',\n",
       " 'education_med school',\n",
       " 'education_no_answer',\n",
       " 'education_ph.d program',\n",
       " 'education_space camp',\n",
       " 'education_two-year college',\n",
       " 'education_working on college/university',\n",
       " 'education_working on high school',\n",
       " 'education_working on law school',\n",
       " 'education_working on masters program',\n",
       " 'education_working on med school',\n",
       " 'education_working on ph.d program',\n",
       " 'education_working on space camp',\n",
       " 'education_working on two-year college',\n",
       " 'ethnicity_asian',\n",
       " 'ethnicity_asian, black',\n",
       " 'ethnicity_asian, black, hispanic / latin',\n",
       " 'ethnicity_asian, black, hispanic / latin, other',\n",
       " 'ethnicity_asian, black, hispanic / latin, white',\n",
       " 'ethnicity_asian, black, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, black, indian',\n",
       " 'ethnicity_asian, black, indian, hispanic / latin, other',\n",
       " 'ethnicity_asian, black, native american',\n",
       " 'ethnicity_asian, black, native american, hispanic / latin',\n",
       " 'ethnicity_asian, black, native american, hispanic / latin, white',\n",
       " 'ethnicity_asian, black, native american, indian',\n",
       " 'ethnicity_asian, black, native american, indian, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, black, native american, indian, pacific islander, hispanic / latin',\n",
       " 'ethnicity_asian, black, native american, indian, pacific islander, white',\n",
       " 'ethnicity_asian, black, native american, other',\n",
       " 'ethnicity_asian, black, native american, pacific islander',\n",
       " 'ethnicity_asian, black, native american, pacific islander, other',\n",
       " 'ethnicity_asian, black, native american, pacific islander, white',\n",
       " 'ethnicity_asian, black, native american, pacific islander, white, other',\n",
       " 'ethnicity_asian, black, native american, white',\n",
       " 'ethnicity_asian, black, native american, white, other',\n",
       " 'ethnicity_asian, black, other',\n",
       " 'ethnicity_asian, black, pacific islander',\n",
       " 'ethnicity_asian, black, pacific islander, hispanic / latin',\n",
       " 'ethnicity_asian, black, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, black, pacific islander, other',\n",
       " 'ethnicity_asian, black, pacific islander, white',\n",
       " 'ethnicity_asian, black, pacific islander, white, other',\n",
       " 'ethnicity_asian, black, white',\n",
       " 'ethnicity_asian, black, white, other',\n",
       " 'ethnicity_asian, hispanic / latin',\n",
       " 'ethnicity_asian, hispanic / latin, other',\n",
       " 'ethnicity_asian, hispanic / latin, white',\n",
       " 'ethnicity_asian, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, indian',\n",
       " 'ethnicity_asian, indian, hispanic / latin',\n",
       " 'ethnicity_asian, indian, other',\n",
       " 'ethnicity_asian, indian, pacific islander',\n",
       " 'ethnicity_asian, indian, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, indian, pacific islander, other',\n",
       " 'ethnicity_asian, indian, white',\n",
       " 'ethnicity_asian, indian, white, other',\n",
       " 'ethnicity_asian, middle eastern',\n",
       " 'ethnicity_asian, middle eastern, black',\n",
       " 'ethnicity_asian, middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, black, native american, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin',\n",
       " 'ethnicity_asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, other',\n",
       " 'ethnicity_asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, middle eastern, black, native american, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, middle eastern, black, pacific islander',\n",
       " 'ethnicity_asian, middle eastern, black, pacific islander, hispanic / latin',\n",
       " 'ethnicity_asian, middle eastern, black, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, black, white, other',\n",
       " 'ethnicity_asian, middle eastern, hispanic / latin',\n",
       " 'ethnicity_asian, middle eastern, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, indian',\n",
       " 'ethnicity_asian, middle eastern, indian, hispanic / latin',\n",
       " 'ethnicity_asian, middle eastern, indian, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, middle eastern, indian, other',\n",
       " 'ethnicity_asian, middle eastern, native american, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, native american, indian, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, middle eastern, native american, pacific islander, other',\n",
       " 'ethnicity_asian, middle eastern, native american, pacific islander, white, other',\n",
       " 'ethnicity_asian, middle eastern, other',\n",
       " 'ethnicity_asian, middle eastern, white',\n",
       " 'ethnicity_asian, middle eastern, white, other',\n",
       " 'ethnicity_asian, native american',\n",
       " 'ethnicity_asian, native american, hispanic / latin',\n",
       " 'ethnicity_asian, native american, hispanic / latin, other',\n",
       " 'ethnicity_asian, native american, hispanic / latin, white',\n",
       " 'ethnicity_asian, native american, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, native american, other',\n",
       " 'ethnicity_asian, native american, pacific islander',\n",
       " 'ethnicity_asian, native american, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, native american, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, native american, pacific islander, white',\n",
       " 'ethnicity_asian, native american, pacific islander, white, other',\n",
       " 'ethnicity_asian, native american, white',\n",
       " 'ethnicity_asian, native american, white, other',\n",
       " 'ethnicity_asian, other',\n",
       " 'ethnicity_asian, pacific islander',\n",
       " 'ethnicity_asian, pacific islander, hispanic / latin',\n",
       " 'ethnicity_asian, pacific islander, hispanic / latin, other',\n",
       " 'ethnicity_asian, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_asian, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_asian, pacific islander, other',\n",
       " 'ethnicity_asian, pacific islander, white',\n",
       " 'ethnicity_asian, pacific islander, white, other',\n",
       " 'ethnicity_asian, white',\n",
       " 'ethnicity_asian, white, other',\n",
       " 'ethnicity_black',\n",
       " 'ethnicity_black, hispanic / latin',\n",
       " 'ethnicity_black, hispanic / latin, other',\n",
       " 'ethnicity_black, hispanic / latin, white',\n",
       " 'ethnicity_black, hispanic / latin, white, other',\n",
       " 'ethnicity_black, indian',\n",
       " 'ethnicity_black, indian, hispanic / latin',\n",
       " 'ethnicity_black, indian, hispanic / latin, white',\n",
       " 'ethnicity_black, indian, other',\n",
       " 'ethnicity_black, indian, white',\n",
       " 'ethnicity_black, indian, white, other',\n",
       " 'ethnicity_black, native american',\n",
       " 'ethnicity_black, native american, hispanic / latin',\n",
       " 'ethnicity_black, native american, hispanic / latin, other',\n",
       " 'ethnicity_black, native american, hispanic / latin, white',\n",
       " 'ethnicity_black, native american, hispanic / latin, white, other',\n",
       " 'ethnicity_black, native american, indian',\n",
       " 'ethnicity_black, native american, indian, hispanic / latin, white, other',\n",
       " 'ethnicity_black, native american, indian, other',\n",
       " 'ethnicity_black, native american, indian, pacific islander',\n",
       " 'ethnicity_black, native american, indian, pacific islander, hispanic / latin',\n",
       " 'ethnicity_black, native american, indian, white',\n",
       " 'ethnicity_black, native american, indian, white, other',\n",
       " 'ethnicity_black, native american, other',\n",
       " 'ethnicity_black, native american, pacific islander',\n",
       " 'ethnicity_black, native american, pacific islander, hispanic / latin',\n",
       " 'ethnicity_black, native american, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_black, native american, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_black, native american, pacific islander, other',\n",
       " 'ethnicity_black, native american, pacific islander, white',\n",
       " 'ethnicity_black, native american, pacific islander, white, other',\n",
       " 'ethnicity_black, native american, white',\n",
       " 'ethnicity_black, native american, white, other',\n",
       " 'ethnicity_black, other',\n",
       " 'ethnicity_black, pacific islander',\n",
       " 'ethnicity_black, pacific islander, hispanic / latin',\n",
       " 'ethnicity_black, pacific islander, other',\n",
       " 'ethnicity_black, pacific islander, white',\n",
       " 'ethnicity_black, white',\n",
       " 'ethnicity_black, white, other',\n",
       " 'ethnicity_hispanic / latin',\n",
       " 'ethnicity_hispanic / latin, other',\n",
       " 'ethnicity_hispanic / latin, white',\n",
       " 'ethnicity_hispanic / latin, white, other',\n",
       " 'ethnicity_indian',\n",
       " 'ethnicity_indian, hispanic / latin',\n",
       " 'ethnicity_indian, hispanic / latin, other',\n",
       " 'ethnicity_indian, hispanic / latin, white',\n",
       " 'ethnicity_indian, hispanic / latin, white, other',\n",
       " 'ethnicity_indian, other',\n",
       " 'ethnicity_indian, pacific islander',\n",
       " 'ethnicity_indian, white',\n",
       " 'ethnicity_indian, white, other',\n",
       " 'ethnicity_middle eastern',\n",
       " 'ethnicity_middle eastern, black',\n",
       " 'ethnicity_middle eastern, black, hispanic / latin',\n",
       " 'ethnicity_middle eastern, black, indian, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_middle eastern, black, native american, hispanic / latin, white',\n",
       " 'ethnicity_middle eastern, black, native american, indian',\n",
       " 'ethnicity_middle eastern, black, native american, indian, hispanic / latin, white',\n",
       " 'ethnicity_middle eastern, black, native american, indian, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_middle eastern, black, native american, indian, white, other',\n",
       " 'ethnicity_middle eastern, black, native american, white',\n",
       " 'ethnicity_middle eastern, black, native american, white, other',\n",
       " 'ethnicity_middle eastern, black, other',\n",
       " 'ethnicity_middle eastern, black, pacific islander, white',\n",
       " 'ethnicity_middle eastern, black, white',\n",
       " 'ethnicity_middle eastern, hispanic / latin',\n",
       " 'ethnicity_middle eastern, hispanic / latin, other',\n",
       " 'ethnicity_middle eastern, hispanic / latin, white',\n",
       " 'ethnicity_middle eastern, hispanic / latin, white, other',\n",
       " 'ethnicity_middle eastern, indian',\n",
       " 'ethnicity_middle eastern, indian, other',\n",
       " 'ethnicity_middle eastern, indian, white',\n",
       " 'ethnicity_middle eastern, indian, white, other',\n",
       " 'ethnicity_middle eastern, native american',\n",
       " 'ethnicity_middle eastern, native american, hispanic / latin',\n",
       " 'ethnicity_middle eastern, native american, hispanic / latin, white',\n",
       " 'ethnicity_middle eastern, native american, hispanic / latin, white, other',\n",
       " 'ethnicity_middle eastern, native american, white',\n",
       " 'ethnicity_middle eastern, native american, white, other',\n",
       " 'ethnicity_middle eastern, other',\n",
       " 'ethnicity_middle eastern, pacific islander',\n",
       " 'ethnicity_middle eastern, pacific islander, hispanic / latin',\n",
       " 'ethnicity_middle eastern, pacific islander, other',\n",
       " 'ethnicity_middle eastern, white',\n",
       " 'ethnicity_middle eastern, white, other',\n",
       " 'ethnicity_native american',\n",
       " 'ethnicity_native american, hispanic / latin',\n",
       " 'ethnicity_native american, hispanic / latin, other',\n",
       " 'ethnicity_native american, hispanic / latin, white',\n",
       " 'ethnicity_native american, hispanic / latin, white, other',\n",
       " 'ethnicity_native american, indian',\n",
       " 'ethnicity_native american, indian, pacific islander, hispanic / latin',\n",
       " 'ethnicity_native american, indian, white',\n",
       " 'ethnicity_native american, other',\n",
       " 'ethnicity_native american, pacific islander',\n",
       " 'ethnicity_native american, pacific islander, hispanic / latin',\n",
       " 'ethnicity_native american, pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_native american, pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_native american, pacific islander, white',\n",
       " 'ethnicity_native american, pacific islander, white, other',\n",
       " 'ethnicity_native american, white',\n",
       " 'ethnicity_native american, white, other',\n",
       " 'ethnicity_other',\n",
       " 'ethnicity_pacific islander',\n",
       " 'ethnicity_pacific islander, hispanic / latin',\n",
       " 'ethnicity_pacific islander, hispanic / latin, other',\n",
       " 'ethnicity_pacific islander, hispanic / latin, white',\n",
       " 'ethnicity_pacific islander, hispanic / latin, white, other',\n",
       " 'ethnicity_pacific islander, other',\n",
       " 'ethnicity_pacific islander, white',\n",
       " 'ethnicity_pacific islander, white, other',\n",
       " 'ethnicity_white',\n",
       " 'ethnicity_white, other',\n",
       " 'job_artistic / musical / writer',\n",
       " 'job_banking / financial / real estate',\n",
       " 'job_clerical / administrative',\n",
       " 'job_computer / hardware / software',\n",
       " 'job_construction / craftsmanship',\n",
       " 'job_education / academia',\n",
       " 'job_entertainment / media',\n",
       " 'job_executive / management',\n",
       " 'job_hospitality / travel',\n",
       " 'job_law / legal services',\n",
       " 'job_medicine / health',\n",
       " 'job_military',\n",
       " 'job_no_answer',\n",
       " 'job_other',\n",
       " 'job_political / government',\n",
       " 'job_rather not say',\n",
       " 'job_retired',\n",
       " 'job_sales / marketing / biz dev',\n",
       " 'job_science / tech / engineering',\n",
       " 'job_student',\n",
       " 'job_transportation',\n",
       " 'job_unemployed',\n",
       " \"offspring_doesn't have kids\",\n",
       " \"offspring_doesn't have kids, and doesn't want any\",\n",
       " \"offspring_doesn't have kids, but might want them\",\n",
       " \"offspring_doesn't have kids, but wants them\",\n",
       " \"offspring_doesn't want kids\",\n",
       " 'offspring_has a kid',\n",
       " 'offspring_has a kid, and might want more',\n",
       " 'offspring_has a kid, and wants more',\n",
       " \"offspring_has a kid, but doesn't want more\",\n",
       " 'offspring_has kids',\n",
       " 'offspring_has kids, and might want more',\n",
       " 'offspring_has kids, and wants more',\n",
       " \"offspring_has kids, but doesn't want more\",\n",
       " 'offspring_might want kids',\n",
       " 'offspring_no_answer',\n",
       " 'offspring_wants kids',\n",
       " 'pets_dislikes cats',\n",
       " 'pets_dislikes dogs',\n",
       " 'pets_dislikes dogs and dislikes cats',\n",
       " 'pets_dislikes dogs and has cats',\n",
       " 'pets_dislikes dogs and likes cats',\n",
       " 'pets_has cats',\n",
       " 'pets_has dogs',\n",
       " 'pets_has dogs and dislikes cats',\n",
       " 'pets_has dogs and has cats',\n",
       " 'pets_has dogs and likes cats',\n",
       " 'pets_likes cats',\n",
       " 'pets_likes dogs',\n",
       " 'pets_likes dogs and dislikes cats',\n",
       " 'pets_likes dogs and has cats',\n",
       " 'pets_likes dogs and likes cats',\n",
       " 'pets_no_answer',\n",
       " 'smokes_no',\n",
       " 'smokes_no_answer',\n",
       " 'smokes_sometimes',\n",
       " 'smokes_trying to quit',\n",
       " 'smokes_when drinking',\n",
       " 'smokes_yes',\n",
       " 'speaks_afrikaans, english',\n",
       " 'speaks_english',\n",
       " 'speaks_english (fluently)',\n",
       " 'speaks_english (fluently), afrikaans (fluently)',\n",
       " 'speaks_english (fluently), afrikaans (fluently), albanian (fluently), arabic (fluently), c++ (fluently)',\n",
       " 'speaks_english (fluently), afrikaans (fluently), chinese (fluently), dutch (fluently), czech (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (fluently), dutch (okay), german (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (fluently), french (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), afrikaans (okay)',\n",
       " 'speaks_english (fluently), afrikaans (okay), dutch (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (okay), dutch (poorly), french (okay), german (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (okay), hebrew (fluently), yiddish (okay)',\n",
       " 'speaks_english (fluently), afrikaans (okay), other (okay)',\n",
       " 'speaks_english (fluently), afrikaans (okay), portuguese (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (poorly), ancient greek (poorly), welsh (poorly)',\n",
       " 'speaks_english (fluently), afrikaans (poorly), vietnamese (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), albanian',\n",
       " 'speaks_english (fluently), albanian (fluently), italian (fluently)',\n",
       " 'speaks_english (fluently), albanian (fluently), italian (okay)',\n",
       " 'speaks_english (fluently), albanian (fluently), serbian (okay), spanish (okay), other (okay)',\n",
       " 'speaks_english (fluently), albanian (fluently), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), albanian (okay)',\n",
       " 'speaks_english (fluently), ancient greek (fluently)',\n",
       " 'speaks_english (fluently), ancient greek (fluently), vietnamese (fluently), sign language (okay), yiddish (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (okay)',\n",
       " 'speaks_english (fluently), ancient greek (okay), hebrew (fluently), french (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), ancient greek (okay), japanese (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (okay), latin (okay), hebrew (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (okay), spanish (fluently), french (poorly), hebrew (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (okay), spanish (okay), swedish (fluently)',\n",
       " 'speaks_english (fluently), ancient greek (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), hebrew (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), irish (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), latin (poorly), c++ (poorly), other (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), latin (poorly), lisp (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), latin (poorly), russian (okay), french (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), latin (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), other',\n",
       " 'speaks_english (fluently), ancient greek (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), ancient greek (poorly), yiddish (okay), latin (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), arabic',\n",
       " 'speaks_english (fluently), arabic (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), c++ (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), c++ (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), chinese (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), german (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), hebrew (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), italian (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), italian (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), russian (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), spanish (fluently), portuguese (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (okay), other (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (okay), portuguese (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly), chinese (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly), spanish (fluently), hebrew (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly), spanish (poorly), german',\n",
       " 'speaks_english (fluently), arabic (fluently), french (poorly), spanish (poorly), russian (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), greek (okay), french (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), hebrew (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (fluently), french (fluently), persian (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (okay), french (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (okay), french (okay), hindi (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (okay), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (okay), urdu (okay), gujarati (okay)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), arabic (fluently), spanish (poorly), welsh (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), c++ (fluently)',\n",
       " 'speaks_english (fluently), arabic (okay), farsi (fluently), french (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), farsi (okay), french (okay), hebrew (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), french (fluently)',\n",
       " 'speaks_english (fluently), arabic (okay), french (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), french (okay), german (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), french (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), german (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), german (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), korean (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), spanish (fluently)',\n",
       " 'speaks_english (fluently), arabic (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (okay), spanish (okay), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), spanish (poorly), swahili (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), swahili (poorly)',\n",
       " 'speaks_english (fluently), arabic (okay), tagalog (okay), french (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), chinese (poorly), french (fluently), german (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (fluently)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (okay), german (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (okay), german (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (okay), spanish (fluently), c++ (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (poorly), chinese (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (poorly), portuguese (poorly), urdu (fluently)',\n",
       " 'speaks_english (fluently), arabic (poorly), french (poorly), spanish (okay), swahili (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), german (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), hebrew (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), hindi (fluently)',\n",
       " 'speaks_english (fluently), arabic (poorly), japanese (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), latin (fluently), other (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), norwegian (poorly), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), russian (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (fluently)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (okay), sign language (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), arabic (poorly), tagalog (fluently)',\n",
       " 'speaks_english (fluently), arabic (poorly), urdu (poorly)',\n",
       " 'speaks_english (fluently), armenian (fluently)',\n",
       " 'speaks_english (fluently), armenian (fluently), spanish (okay), farsi (poorly)',\n",
       " 'speaks_english (fluently), armenian (fluently), turkish (fluently), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), armenian (okay), russian (fluently)',\n",
       " 'speaks_english (fluently), basque (fluently), catalan (fluently), serbian (fluently), hebrew (okay)',\n",
       " 'speaks_english (fluently), basque (fluently), french (fluently), italian (poorly)',\n",
       " 'speaks_english (fluently), basque (poorly)',\n",
       " 'speaks_english (fluently), belarusan (fluently), russian (fluently)',\n",
       " 'speaks_english (fluently), belarusan (okay), rotuman (fluently), tagalog (poorly), hawaiian (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently)',\n",
       " 'speaks_english (fluently), bengali (fluently), c++ (fluently)',\n",
       " 'speaks_english (fluently), bengali (fluently), c++ (poorly), french (poorly), romanian (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently), french (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), bengali (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently), hindi (fluently)',\n",
       " 'speaks_english (fluently), bengali (fluently), hindi (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently), hindi (okay)',\n",
       " 'speaks_english (fluently), bengali (fluently), hindi (okay), urdu (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently), hindi (poorly)',\n",
       " 'speaks_english (fluently), bengali (fluently), japanese (okay)',\n",
       " 'speaks_english (fluently), bengali (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), bengali (okay)',\n",
       " 'speaks_english (fluently), bengali (okay), hindi (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), bengali (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), bengali (poorly), french (poorly), hindi (fluently)',\n",
       " 'speaks_english (fluently), bengali, c++ (fluently), vietnamese (poorly), english (okay)',\n",
       " 'speaks_english (fluently), breton (poorly), french (poorly), thai (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (fluently)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), french (okay)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), french (poorly), japanese (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), german (okay)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), german (okay), russian (okay)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), german (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), russian (fluently), french (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), russian (okay)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), russian (okay), german (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), russian (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), bulgarian (fluently), russian (okay), spanish (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (okay)',\n",
       " 'speaks_english (fluently), bulgarian (poorly), arabic (okay), german (fluently), japanese (fluently)',\n",
       " 'speaks_english (fluently), bulgarian (poorly), russian (poorly)',\n",
       " 'speaks_english (fluently), bulgarian (poorly), swahili (poorly)',\n",
       " 'speaks_english (fluently), c++',\n",
       " 'speaks_english (fluently), c++ (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), afrikaans (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), arabic (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), bengali (fluently), hindi (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), bengali (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (okay), french (poorly), yiddish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (poorly), french (poorly), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (poorly), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), chinese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), danish (fluently), french (okay), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), esperanto (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), farsi (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (fluently), german (poorly), spanish (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (fluently), spanish (fluently), chinese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (okay), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (okay), portuguese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (okay), spanish (okay), lisp (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), esperanto (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), lisp (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), spanish (okay), italian (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), spanish (okay), italian (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (okay), chinese (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (okay), chinese (poorly), norwegian (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (poorly), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), german (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), greek (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), hebrew (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), hebrew (poorly), lisp (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), hebrew (poorly), other (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), hindi (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), hindi (fluently), lisp (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), italian (okay), japanese (okay), french (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), italian (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), japanese (okay), spanish (okay), romanian (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), japanese (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), japanese (poorly), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), latin (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (fluently), occitan (fluently), ancient greek (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (fluently), sign language (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay), german (poorly), other (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay), indonesian (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (okay), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), french (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), italian (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), lisp (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), norwegian (poorly), yiddish (poorly), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), other (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), other (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), russian (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), russian (fluently), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), russian (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), russian (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), sign language (okay), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (fluently), italian (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), hindi (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), russian (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), sanskrit (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (okay), turkish (fluently)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (poorly), french (poorly), hebrew (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (poorly), french (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), spanish (poorly), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), swedish (poorly), french (okay), hindi (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), tagalog (poorly)',\n",
       " 'speaks_english (fluently), c++ (fluently), tamil (fluently), japanese (okay)',\n",
       " 'speaks_english (fluently), c++ (fluently), turkish (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), ancient greek (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), ancient greek (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (fluently), malay (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (poorly), german (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), chinese (poorly), spanish (poorly), farsi (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), french (fluently), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), french (okay), lisp (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), french (okay), tagalog (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), french (poorly), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), german (poorly), french (poorly), other',\n",
       " 'speaks_english (fluently), c++ (okay), german (poorly), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), german (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), hebrew (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), hindi (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), hungarian (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), indonesian (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), italian (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), italian (poorly), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), japanese (okay), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), japanese (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), japanese (poorly), spanish (okay), italian (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (poorly), french (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (poorly), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), latin (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (okay), latin (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (okay), sign language (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), lisp (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), other',\n",
       " 'speaks_english (fluently), c++ (okay), other (fluently), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), other (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), other (fluently), thai (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), other (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), russian (fluently), french (okay), hebrew (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), russian (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), sign language (okay), russian (okay), french (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (fluently)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (okay), french (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (okay), ukrainian (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), spanish, chinese, tagalog',\n",
       " 'speaks_english (fluently), c++ (okay), tagalog (poorly)',\n",
       " 'speaks_english (fluently), c++ (okay), yiddish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), ancient greek (fluently), irish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), ancient greek (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), chinese (fluently), french (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), chinese (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), chinese (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), esperanto (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), finnish (fluently), swedish (okay), german (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), french (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), german (fluently), khmer (fluently), mongolian (fluently)',\n",
       " 'speaks_english (fluently), c++ (poorly), german (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), hawaiian (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), hebrew (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), italian (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), japanese (poorly), spanish (poorly), portuguese (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), lisp (fluently)',\n",
       " 'speaks_english (fluently), c++ (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (poorly), other (fluently), lisp (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), other (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), other (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), sign language (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), sign language (okay), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), sign language (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), sign language (poorly), swedish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), chinese (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), irish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), c++ (poorly), spanish (poorly), tagalog (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), swedish (poorly)',\n",
       " 'speaks_english (fluently), c++ (poorly), yiddish (poorly)',\n",
       " 'speaks_english (fluently), c++, lisp',\n",
       " 'speaks_english (fluently), c++, spanish (okay)',\n",
       " 'speaks_english (fluently), catalan (fluently)',\n",
       " 'speaks_english (fluently), catalan (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), catalan (fluently), spanish (fluently), french (okay), dutch (poorly)',\n",
       " 'speaks_english (fluently), catalan (fluently), spanish (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), catalan (okay), spanish (okay), chinese (poorly), tagalog (poorly)',\n",
       " 'speaks_english (fluently), catalan (poorly), albanian (poorly), c++ (poorly)',\n",
       " 'speaks_english (fluently), catalan (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), cebuano (fluently), chechen (fluently), occitan (fluently), tamil (fluently)',\n",
       " 'speaks_english (fluently), cebuano (fluently), tagalog (fluently), french (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), cebuano (okay)',\n",
       " 'speaks_english (fluently), cebuano (okay), chinese (poorly), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), cebuano (okay), spanish (okay), french (poorly)',\n",
       " 'speaks_english (fluently), cebuano (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), cebuano (okay), tagalog (okay)',\n",
       " 'speaks_english (fluently), cebuano (poorly), basque (poorly), sanskrit (poorly), occitan (poorly)',\n",
       " 'speaks_english (fluently), cebuano (poorly), c++ (poorly), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), cebuano, khmer, ilongo',\n",
       " 'speaks_english (fluently), chechen (poorly)',\n",
       " 'speaks_english (fluently), chechen, bengali, tamil, japanese',\n",
       " 'speaks_english (fluently), chinese',\n",
       " 'speaks_english (fluently), chinese (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (fluently), french (okay), lisp (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (fluently), lisp (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (okay), italian (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (okay), other (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (okay), thai (okay), ancient greek (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), c++ (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), english (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (fluently), german (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), german (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), german (poorly), occitan',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), indonesian (okay), chinese (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), japanese (poorly), portuguese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), russian (poorly), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), spanish (okay), portuguese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), spanish (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (okay), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), german (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), portuguese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), spanish (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), french (poorly), spanish (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (fluently), french (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (okay), french (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (okay), japanese (okay), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (poorly), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (poorly), hungarian (poorly), esperanto (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), german (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), hawaiian (okay), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), hawaiian (okay), other (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), hindi (fluently), french (fluently), swedish (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), hungarian (poorly), other (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), indonesian (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), indonesian (fluently), japanese (okay), malay (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), indonesian (fluently), other (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), indonesian (okay), french (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), indonesian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), italian (fluently), swahili (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), italian (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), italian (okay), russian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), italian (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), italian (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (fluently), malay (okay), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), french (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), korean (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), korean (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), korean (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (okay), spanish (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), c++ (fluently), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), french (okay), chinese (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), french (okay), other (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), french (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), french (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), italian (poorly), russian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), korean (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), korean (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), sign language (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), japanese (poorly), vietnamese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), korean (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), korean (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), lisp (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), lisp (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), malay (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), malay (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), malay (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), malay (okay), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), malay (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), mongolian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), norwegian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), other',\n",
       " 'speaks_english (fluently), chinese (fluently), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), other (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), polish (fluently), russian (fluently), german (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), russian (okay), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), russian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), sign language',\n",
       " 'speaks_english (fluently), chinese (fluently), sign language (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), sign language (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently), arabic (poorly), italian (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently), german (fluently), portuguese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently), latin (poorly), ancient greek (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (fluently), sign language (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), french (okay), irish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), japanese',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), japanese (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), russian (poorly), hindi (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), sign language (okay), other',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (okay), vietnamese (okay), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), c++',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), german (poorly), english',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), hungarian (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), italian (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), vietnamese (okay)',\n",
       " 'speaks_english (fluently), chinese (fluently), spanish (poorly), vietnamese (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), tagalog (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), tagalog (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), thai (okay), japanese (poorly), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), tibetan (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), vietnamese (fluently)',\n",
       " 'speaks_english (fluently), chinese (fluently), vietnamese (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), vietnamese (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), vietnamese (poorly), c++ (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), chinese (fluently), vietnamese (poorly), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (fluently), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (fluently), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), c++ (poorly), spanish (poorly), hindi (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), croatian (poorly), hawaiian (poorly), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), dutch (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (fluently), thai (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), arabic (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), hindi (okay), maori (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), italian (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), japanese (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), latin (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), french (okay), vietnamese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly), other (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), french (poorly), thai (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), german (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), german (okay), vietnamese (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), german (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), german (poorly), c++ (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), german (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), hebrew (fluently), french (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), hindi (okay), french (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), indonesian (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), indonesian (poorly), spanish (okay), tibetan (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (fluently), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (okay), french (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), c++ (fluently), lisp (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), french (poorly), latin (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), italian (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), japanese (poorly), tibetan',\n",
       " 'speaks_english (fluently), chinese (okay), japanese, korean',\n",
       " 'speaks_english (fluently), chinese (okay), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), korean (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), korean (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), lisp (fluently), c++ (fluently), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), lisp (fluently), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), lisp (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), lisp (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), malay (fluently), c++ (fluently), other (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), malay (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), norwegian (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), other',\n",
       " 'speaks_english (fluently), chinese (okay), other (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), other (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), portuguese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), russian (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), russian (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), sign language (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), sign language (poorly), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (fluently), portuguese (fluently), french (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), danish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), french (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), japanese (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), korean (poorly), japanese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), russian (poorly), polish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), sign language (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (okay), sign language (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), french (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), hawaiian',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), hebrew (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), hindi (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), japanese (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), lisp (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), other (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), spanish (poorly), yiddish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), swedish (okay), spanish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), swedish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), swedish (poorly), french (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), tagalog (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), tagalog (fluently), spanish (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (okay), thai (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), tibetan (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), turkish (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), vietnamese (okay), spanish (okay)',\n",
       " 'speaks_english (fluently), chinese (okay), vietnamese (poorly)',\n",
       " 'speaks_english (fluently), chinese (okay), yiddish (poorly)',\n",
       " 'speaks_english (fluently), chinese (poorly)',\n",
       " 'speaks_english (fluently), chinese (poorly), arabic (poorly), french (poorly), portuguese (poorly)',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (fluently)',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (fluently), korean (poorly)',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (fluently), russian (poorly), german (poorly)',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (okay)',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (okay), ancient greek',\n",
       " 'speaks_english (fluently), chinese (poorly), c++ (poorly)',\n",
       " ...]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dummy_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53a34207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age int64\n",
      "height float64\n"
     ]
    }
   ],
   "source": [
    "for col in list(dummy_df.columns):\n",
    "    if dummy_df[col].dtype != 'uint8':\n",
    "        print(col, dummy_df[col].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6429e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=1000, \n",
    "                        stop_words='english', \n",
    "                        strip_accents='unicode', \n",
    "                        analyzer='word')\n",
    "Z = tfidf.fit_transform(essays.essays_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef847ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_df = pd.DataFrame(Z.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbffa39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Columns: 1000 entries, 0 to 999\n",
      "dtypes: float64(1000)\n",
      "memory usage: 78.2 KB\n"
     ]
    }
   ],
   "source": [
    "vector_df.iloc[0:10,0:1000].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be69c76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.173365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6         7    8    9    ...  990  991  992  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.173365  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "        993  994  995  996  997  998  999  \n",
       "0  0.064153  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[1 rows x 1000 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a86ae295",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = dummy_df.join(vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e163802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48890 entries, 0 to 48889\n",
      "Columns: 8059 entries, age to 999\n",
      "dtypes: float64(1001), int64(1), uint8(7057)\n",
      "memory usage: 702.8 MB\n"
     ]
    }
   ],
   "source": [
    "combined_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca3a163",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['sign_actual']\n",
    "X=combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b2d903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36667, 8059), (12223, 8059), (36667,), (12223,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d1fa9c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-27361b500ee0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multinomial'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mLR_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1414\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1416\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1418\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    759\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m                 \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"iprint\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0miprint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gtol\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"maxiter\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             )\n\u001b[1;32m    763\u001b[0m             n_iter_i = _check_optimize_result(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    618\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         return _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m--> 620\u001b[0;31m                                 callback=callback, **options)\n\u001b[0m\u001b[1;32m    621\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m         return _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/lbfgsb.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# Overwrite f and g:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'NEW_X'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;31m# new iteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mupdate_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mfun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;34m\"\"\" returns the the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/scipy/optimize/optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfunc\u001b[0;34m(x, *args)\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_multi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0m_multinomial_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_multinomial_loss_grad\u001b[0;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0mgrad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
    "LR.fit(X_train, y_train)\n",
    "LR_pred = LR.predict(X_test)\n",
    "\n",
    "LR.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ef946dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0926122883089258"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB = GradientBoostingClassifier()\n",
    "GB.fit(X_train, y_train)\n",
    "GB_pred = GB.predict(X_test)\n",
    "\n",
    "GB.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f4bbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08279473124437536"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "RF_pred = RF.predict(X_test)\n",
    "\n",
    "RF.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7656ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_gridsearch = GridSearchCV(estimator=GradientBoostingClassifier(),\n",
    "                                param_grid = {'max_depth': [2, 4, 8],\n",
    "                                             'min_samples_split': [2, 4, 8],\n",
    "                                             'subsample': [1, 0.5, 0.25, 0.1]},\n",
    "                                cv=5, verbose=0, return_train_score=True)\n",
    "gb_gridsearch.fit(X_train, y_train)\n",
    "df_gridsearch = pd.DataFrame(gb_gridsearch.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
